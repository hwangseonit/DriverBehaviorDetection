import streamlit as st
st.set_page_config(page_title="üñºÔ∏è Nh·∫≠n Di·ªán", layout="centered")
import numpy as np
from PIL import Image
import cv2
import tempfile
import os
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
import requests
from io import BytesIO

# ==== Download Model ====
def download_model_if_not_exists(drive_url, save_path):
    if not os.path.exists(save_path):
        import gdown
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with st.spinner(f"ƒêang t·∫£i {os.path.basename(save_path)} t·ª´ Google Drive..."):
            gdown.download(drive_url, save_path, quiet=False)

MODEL_LINKS = {
    'DenseNet': 'https://drive.google.com/uc?id=1oZmWHY5rub52FnHm1J2IM2kXTZRs6_Ew',
    'EfficientNet': 'https://drive.google.com/uc?id=14EGEXZO3L1m8Wbq_fRxLj1uaj-8ewoAf',
    'ResNet': 'https://drive.google.com/uc?id=1MRfaHl_UtMoA9__ok8lZcb2zSELRxmAG'
}
MODEL_PATHS = {
    'DenseNet': 'model/best_model_densenetPMai.h5',
    'EfficientNet': 'model/best_model_efficientnet.h5',
    'ResNet': 'model/best_model_resnet.h5'
}

for name in MODEL_LINKS:
    download_model_if_not_exists(MODEL_LINKS[name], MODEL_PATHS[name])

# ===== B·ªé C√ÅC H√ÄM TI·ªÄN X·ª¨ L√ù C·ª¶A KERAS, CH·ªà CHU·∫®N H√ìA ·∫¢NH V·ªÄ [0, 1] =====

st.markdown("<h1>üöó Nh·∫≠n Di·ªán</h1>", unsafe_allow_html=True)

# Th√™m mapping nh√£n ƒë·∫πp cho hi·ªÉn th·ªã v√† DataFrame
PRETTY_LABELS = {
    "other_activities": "Other",
    "safe_driving": "Safe",
    "talking_phone": "Talking",
    "texting_phone": "Texting",
    "turning": "Turning"
}
PRETTY_LABEL_LIST = ["Other", "Safe", "Talking", "Texting", "Turning"]

def save_history(image, predicted_class, confidence, df, mode="·∫¢nh"):
    if "history" not in st.session_state:
        st.session_state["history"] = []
    # L∆∞u ·∫£nh d·∫°ng bytes ƒë·ªÉ trang kh√°c c√≥ th·ªÉ hi·ªÉn th·ªã l·∫°i
    buf = BytesIO()
    image.save(buf, format="PNG")
    img_bytes = buf.getvalue()
    st.session_state["history"].append({
        "image_bytes": img_bytes,
        "label": predicted_class,
        "confidence": confidence,
        "details": df,
        "mode": mode
    })

    # Map nh√£n model sang nh√£n dashboard
    mapping = PRETTY_LABELS
    dashboard_class = mapping.get(str(predicted_class).lower(), str(predicted_class).title())

    # ===== GHI RA FILE CSV ƒê·ªÇ DASHBOARD ƒê·ªåC ƒê∆Ø·ª¢C =====
    csv_file = "history.csv"
    csv_row = {
        "predict": dashboard_class,
        "confidence": confidence,
        "loai_du_doan": mode
    }
    if os.path.isfile(csv_file):
        pd.DataFrame([csv_row]).to_csv(csv_file, mode='a', header=False, index=False)
    else:
        pd.DataFrame([csv_row]).to_csv(csv_file, mode='w', header=True, index=False)

# ===== CSS=====
st.markdown("""
<style>
/* Sidebar n·ªÅn glass s√°ng, gradient xanh-cam nh·∫°t, b√≥ng ƒë·ªï nh·∫π */
section[data-testid="stSidebar"] {
    background: linear-gradient(120deg, #e0e7ff 0%, #fef9c3 90%, #ffe8d6 100%);
    color: #383e53;
    box-shadow: 8px 0 38px 0 #c7d2fe33, 0 0.5px 0 #fbc2eb33;
    border-top-right-radius: 26px;
    border-bottom-right-radius: 26px;
    border-left: 1.5px solid #fbc2eb33;
    backdrop-filter: blur(14px);
    -webkit-backdrop-filter: blur(14px);
    border-top: 1px solid #e0e7ff88;
    border-bottom: 1px solid #fff3cd99;
}

/* Menu item container v√† danh s√°ch menu */
section[data-testid="stSidebar"] .css-1wvake5,
section[data-testid="stSidebar"] nav[aria-label="Main menu"] {
    padding: 2.1rem 0 0 0;
}
section[data-testid="stSidebar"] ul {
    margin-top: 2rem;
    padding-left: 0.6rem;
}
section[data-testid="stSidebar"] li {
    margin-bottom: 1.18rem;
}

/* Link c∆° b·∫£n */
section[data-testid="stSidebar"] a {
    font-size: 1.13rem;
    font-weight: 600;
    color: #385898 !important;
    border-radius: 14px;
    padding: 0.8rem 2.1rem;
    transition:
        background 0.19s,
        color 0.19s,
        box-shadow 0.19s,
        transform 0.15s;
    display: flex;
    align-items: center;
    gap: 0.7rem;
    box-shadow: none;
    letter-spacing: 0.12px;
    text-shadow: 0 1px 8px #e0e7ff22;
    background: none;
}

/* Hover + focus: n·ªïi, n·ªÅn tr·∫Øng ƒë·ª•c, b√≥ng nh·∫π, ch·ªØ xanh ƒë·∫≠m */
section[data-testid="stSidebar"] a:hover,
section[data-testid="stSidebar"] a:focus {
    background: rgba(255,255,255,0.72);
    color: #1760b9 !important;
    text-shadow: 0 2px 12px #bae6fdcc, 0 1.5px 0 #fbc2eb;
    font-weight: 800;
    box-shadow: 0 4px 18px #bae6fd55;
    transform: translateY(-1.5px) scale(1.03);
    border: 1.5px solid #bae6fd77;
}

/* Active: gradient xanh-cam nh·∫°t, ch·ªØ tr·∫Øng + xanh, b√≥ng n·ªïi */
section[data-testid="stSidebar"] .css-1v0mbdj,
section[data-testid="stSidebar"] a[aria-current="page"] {
    background: linear-gradient(90deg,#6dd5ed 10%,#fbc2eb 90%) !important;
    color: #1e293b !important;
    font-weight: 900;
    box-shadow: 0 6px 24px 0 #bae6fd77, 0 1.5px 0 #fbc2eb33;
    text-shadow: 0 2px 18px #fbc2ebcc;
    border-radius: 16px;
    letter-spacing: 0.22px;
    transform: scale(1.045);
    border: 1.7px solid #fbc2eb88;
}

/* ·∫®n d√≤ng ƒë·ªè ·ªü tr√™n c√πng (n·∫øu mu·ªën) */
div[data-testid="stDecoration"] {
    background: transparent !important;
    height: 0px !important;
}

/* Logo ho·∫∑c icon sidebar (n·∫øu c√≥) */
section[data-testid="stSidebar"] img,
section[data-testid="stSidebar"] svg {
    filter: drop-shadow(0 2px 10px #bae6fd55);
}

/* Responsive: nh·ªè l·∫°i */
@media (max-width: 800px) {
    section[data-testid="stSidebar"] {
        border-radius: 0 0 18px 18px;
        min-width: 120px;
    }
    section[data-testid="stSidebar"] a {
        font-size: 0.99rem;
        padding: 0.6rem 1.1rem;
    }
}
# ===== Css Trang =====
html, body, [class*="css"]  {
    font-family: 'Segoe UI', sans-serif;
    background: linear-gradient(-45deg, #0f172a, #1e3a8a, #06b6d4, #3b82f6);
    background-size: 400% 400%;
    animation: gradientBG 15s ease infinite;
    color: #f8fafc;
}
@keyframes gradientBG {
    0% {background-position: 0% 50%;}
    50% {background-position: 100% 50%;}
    100% {background-position: 0% 50%;}
}
h1 {
    text-align: center;
    font-size: 3rem;
    font-weight: 900;
    color: white;
    margin-top: 1.2rem;
    margin-bottom: 2.2rem;
    white-space: nowrap;
    text-shadow: 2px 2px 10px rgba(0,0,0,0.4);
}
.result-label {
    font-size: 2.5rem;
    font-weight: 700;
    color: #22d3ee;
    text-align: center;
    margin-top: 2rem;
}
.result-box {
    background: rgba(255,255,255,0.1);
    border-radius: 15px;
    padding: 2rem;
    margin-top: 1.5rem;
    box-shadow: 0 10px 30px rgba(0,0,0,0.3);
}
.stButton>button {
    background: linear-gradient(to right, #06b6d4, #3b82f6);
    color: white;
    font-weight: bold;
    border: none;
    border-radius: 12px;
    padding: 0.7rem 1.5rem;
    margin-top: 1rem;
    box-shadow: 0 5px 15px rgba(0,0,0,0.2);
}
.stButton>button:hover {
    transform: scale(1.05);
    box-shadow: 0 10px 25px rgba(0,0,0,0.3);
}
.stRadio > div {
    flex-direction: row !important;
    justify-content: center;
    gap: 1.5rem;
}
.stRadio > div > label {
    background: rgba(255,255,255,0.1);
    padding: 0.5rem 1rem;
    border-radius: 10px;
    color: white;
    font-weight: 500;
}
.stRadio > div > label:hover {
    background: rgba(255,255,255,0.2);
}
</style>
""", unsafe_allow_html=True)

CLASS_NAMES = ['other_activities', 'safe_driving', 'talking_phone', 'texting_phone', 'turning']

@st.cache_resource
def load_models():
    try:
        return {
            'DenseNet': load_model('model/best_model_densenetPMai.h5'),
            'EfficientNet': load_model('model/best_model_efficientnet.h5'),
            'ResNet': load_model('model/best_model_resnet.h5')
        }
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        return {}

# ===== TI·ªÄN X·ª¨ L√ù: CH·ªà CHIA 255 =====
def preprocess_image(image, model_name):
    try:
        if image.mode != "RGB":
            image = image.convert("RGB")
        image = image.resize((224, 224))
        arr = img_to_array(image)
        arr = arr / 255.0
        return np.expand_dims(arr, axis=0)
    except Exception as e:
        st.error(f"L·ªói ti·ªÅn x·ª≠ l√Ω ·∫£nh: {e}")
        return None

def predict(model, img_array):
    predictions = model.predict(img_array)
    predicted_class = CLASS_NAMES[np.argmax(predictions)]
    # Map x√°c su·∫•t sang nh√£n ƒë·∫πp cho DataFrame
    pretty_probs = {PRETTY_LABELS[cls]: float(predictions[0][i]) for i, cls in enumerate(CLASS_NAMES)}
    pretty_probs_ordered = [pretty_probs[label] for label in PRETTY_LABEL_LIST]
    return predicted_class, [pretty_probs_ordered]

def query_dify_bot(prompt):
    url = "https://api.dify.ai/v1/chat-messages"
    headers = {
        "Authorization": "Bearer app-xdnSPczSr0oelVVUQc1G1TVF",  # N√™n d√πng bi·∫øn m√¥i tr∆∞·ªùng
        "Content-Type": "application/json"
    }
    data = {
        "user": "streamlit-user",
        "conversation_id": None,
        "inputs": {},
        "query": prompt,
        "response_mode": "blocking"
    }
    try:
        response = requests.post(url, headers=headers, json=data, timeout=20)
        if response.status_code == 200:
            return response.json().get("answer", "‚ö†Ô∏è Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ AI.")
        else:
            return f"‚ö†Ô∏è L·ªói AI: {response.status_code} - {response.text}"
    except Exception as e:
        return f"‚ùå L·ªói k·∫øt n·ªëi t·ªõi AI: {str(e)}"

def clear_prediction_state():
    for key in ["predicted_class", "confidence", "df"]:
        if key in st.session_state:
            del st.session_state[key]

models = load_models()
if not models:
    st.stop()

model_choice = st.selectbox("üß† Ch·ªçn m√¥ h√¨nh", list(models.keys()))
option = st.radio("üìÇ Ch·ªçn lo·∫°i ƒë·∫ßu v√†o", ["·∫¢nh", "Video"])

if option == "·∫¢nh":
    uploaded_image = st.file_uploader("üñºÔ∏è T·∫£i ·∫£nh", type=["jpg", "jpeg", "png"])
    # X√≥a k·∫øt qu·∫£ khi kh√¥ng c√≤n ·∫£nh
    if not uploaded_image:
        clear_prediction_state()
    if uploaded_image:
        image = Image.open(uploaded_image)
        st.image(image, caption="·∫¢nh ƒë√£ t·∫£i", use_container_width=True)
        if st.button("üöÄ D·ª± ƒëo√°n t·ª´ ·∫£nh"):
            model = models[model_choice]
            input_array = preprocess_image(image, model_choice)
            if input_array is not None:
                predicted_class, pretty_predictions = predict(model, input_array)
                pretty_label = PRETTY_LABELS.get(predicted_class, predicted_class)
                confidence = float(np.max(pretty_predictions))
                st.session_state.predicted_class = pretty_label
                st.session_state.confidence = confidence
                st.session_state.df = pd.DataFrame(pretty_predictions, columns=PRETTY_LABEL_LIST)
                save_history(image, pretty_label, confidence, st.session_state.df, mode="·∫¢nh")

elif option == "Video":
    uploaded_video = st.file_uploader("üìπ T·∫£i video", type=["mp4", "avi", "mov"])
    # X√≥a k·∫øt qu·∫£ khi kh√¥ng c√≤n video
    if not uploaded_video:
        clear_prediction_state()
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)
        model = models[model_choice]
        frame_count = 0
        predictions_accum = []
        first_frame_img = None
        with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω video..."):
            while cap.isOpened() and frame_count < 30:
                ret, frame = cap.read()
                if not ret:
                    break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                img_pil = Image.fromarray(frame_rgb)
                if first_frame_img is None:
                    first_frame_img = img_pil.copy()  # L∆∞u frame ƒë·∫ßu l√†m ƒë·∫°i di·ªán
                input_array = preprocess_image(img_pil, model_choice)
                if input_array is not None:
                    _, pretty_probs = predict(model, input_array)
                    predictions_accum.append(pretty_probs[0])
                frame_count += 1
        cap.release()
        os.unlink(tfile.name)
        if predictions_accum:
            avg_pred = np.mean(predictions_accum, axis=0)
            idx = int(np.argmax(avg_pred))
            pretty_label = PRETTY_LABEL_LIST[idx]
            confidence = float(np.max(avg_pred))
            st.session_state.predicted_class = pretty_label
            st.session_state.confidence = confidence
            st.session_state.df = pd.DataFrame([avg_pred], columns=PRETTY_LABEL_LIST)
            if first_frame_img is not None:
                save_history(first_frame_img, pretty_label, confidence, st.session_state.df, mode="Video")

# ===== Hi·ªÉn th·ªã k·∫øt qu·∫£ =====
if "predicted_class" in st.session_state:
    st.markdown(f'<div class="result-label">üö© {st.session_state.predicted_class.upper()}</div>', unsafe_allow_html=True)
    st.progress(st.session_state.confidence, text=f"ƒê·ªô tin c·∫≠y: {st.session_state.confidence:.2%}")
    with st.expander("üìä Xem chi ti·∫øt ph√¢n b·ªë d·ª± ƒëo√°n"):
        df = st.session_state.df
        st.dataframe(df.style.format("{:.2%}"))

    # ===== AI Tr·ª£ l√Ω =====
    st.subheader("ü§ñ AI Tr·ª£ L√Ω Gi·∫£i Th√≠ch")
    user_question = st.text_input("üí¨ C√¢u h·ªèi c·ªßa b·∫°n v·ªÅ h√†nh vi n√†y")
    ask = st.button("üì® G·ª≠i c√¢u h·ªèi")
    if ask and user_question:
        with st.spinner("ü§ñ AI ƒëang suy nghƒ©..."):
            ai_answer = query_dify_bot(f"Ng∆∞·ªùi d√πng h·ªèi: {user_question}. K·∫øt qu·∫£ ph√¢n lo·∫°i h√†nh vi l√†: {st.session_state.predicted_class}")
            st.markdown(f"<div class='result-box'>{ai_answer}</div>", unsafe_allow_html=True)
